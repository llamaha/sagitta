//! Embedding handler implementation for the Sagitta embedding engine.

use crate::config::EmbeddingConfig;
use crate::error::{Result, SagittaEmbedError};
use crate::model::EmbeddingModelType;
use crate::provider::EmbeddingProvider;
use std::path::PathBuf;
use std::sync::{Arc, Mutex};
use std::time::Instant;

#[cfg(feature = "onnx")]
use crate::provider::onnx::OnnxEmbeddingModel;

/// Handles the creation and usage of embedding models.
#[derive(Debug)]
pub struct EmbeddingHandler {
    config: EmbeddingConfig,
    #[cfg(feature = "onnx")]
    onnx_provider: Option<Arc<Mutex<OnnxEmbeddingModel>>>,
    last_used: Instant,
}

impl EmbeddingHandler {
    /// Creates a new `EmbeddingHandler` based on the provided configuration.
    ///
    /// Initializes the appropriate embedding model provider (e.g., ONNX) based on `config`.
    pub fn new(config: &EmbeddingConfig) -> Result<Self> {
        // Validate configuration first
        config.validate()?;

        let model_type = config.model_type.clone();
        
        #[cfg(feature = "onnx")]
        let onnx_provider_result = match model_type {
            EmbeddingModelType::Onnx | EmbeddingModelType::Default => {
                let model_path = config.onnx_model_path.as_ref()
                    .ok_or_else(|| SagittaEmbedError::configuration("ONNX model path not set in config"))?;
                let tokenizer_path = config.onnx_tokenizer_path.as_ref()
                    .ok_or_else(|| SagittaEmbedError::configuration("ONNX tokenizer path not set in config"))?;

                OnnxEmbeddingModel::new_with_config(model_path, tokenizer_path, config)
                    .map(|p| Arc::new(Mutex::new(p)))
            },
        };

        #[cfg(feature = "onnx")]
        let onnx_provider = match onnx_provider_result {
            Ok(provider) => Some(provider),
            Err(e) => return Err(e),
        };

        #[cfg(not(feature = "onnx"))]
        let _onnx_provider_result = Err(SagittaEmbedError::feature_not_enabled("onnx"));

        Ok(Self {
            config: config.clone(),
            #[cfg(feature = "onnx")]
            onnx_provider,
            last_used: Instant::now(),
        })
    }

    /// Returns the expected dimension of the embeddings generated by the current model.
    pub fn dimension(&self) -> Result<usize> {
        #[cfg(feature = "onnx")]
        {
            if let Some(provider) = &self.onnx_provider {
                let provider_guard = provider.lock()
                    .map_err(|e| SagittaEmbedError::thread_safety(format!("Failed to lock provider: {}", e)))?;
                Ok(provider_guard.dimension())
            } else {
                log::warn!("ONNX provider not initialized when getting dimension. Attempting lazy init...");
                let provider = self.create_embedding_model()?;
                let provider_guard = provider.lock()
                    .map_err(|e| SagittaEmbedError::thread_safety(format!("Failed to lock provider: {}", e)))?;
                Ok(provider_guard.dimension())
            }
        }
        #[cfg(not(feature = "onnx"))]
        {
            Err(SagittaEmbedError::feature_not_enabled("onnx"))
        }
    }

    /// Generates embeddings for a batch of texts using the handler's model.
    pub fn embed(&self, texts: &[&str]) -> Result<Vec<Vec<f32>>> {
        if texts.is_empty() {
            return Ok(Vec::new());
        }

        #[cfg(feature = "onnx")]
        {
            if let Some(provider) = &self.onnx_provider {
                let provider_guard = provider.lock()
                    .map_err(|e| SagittaEmbedError::thread_safety(format!("Failed to lock provider: {}", e)))?;
                provider_guard.embed_batch(texts)
            } else {
                log::warn!("ONNX provider not initialized during embed call. This may indicate an earlier init failure.");
                let provider = self.create_embedding_model()?;
                let provider_guard = provider.lock()
                    .map_err(|e| SagittaEmbedError::thread_safety(format!("Failed to lock provider: {}", e)))?;
                provider_guard.embed_batch(texts)
            }
        }
        #[cfg(not(feature = "onnx"))]
        {
            Err(SagittaEmbedError::feature_not_enabled("onnx"))
        }
    }

    /// Creates and returns a new instance of the configured embedding model provider.
    /// This is used internally if the provider was not initialized at creation or after path changes.
    #[cfg(feature = "onnx")]
    pub fn create_embedding_model(&self) -> Result<Arc<Mutex<OnnxEmbeddingModel>>> {
        match self.config.model_type {
            EmbeddingModelType::Onnx | EmbeddingModelType::Default => {
                let model_path = self.config.onnx_model_path.as_ref().ok_or_else(|| {
                    SagittaEmbedError::configuration("ONNX model path not set in handler.")
                })?;
                let tokenizer_path = self.config.onnx_tokenizer_path.as_ref().ok_or_else(|| {
                    SagittaEmbedError::configuration("ONNX tokenizer path not set in handler.")
                })?;
                let provider = Arc::new(Mutex::new(OnnxEmbeddingModel::new_with_config(
                    model_path,
                    tokenizer_path,
                    &self.config,
                )?));
                Ok(provider)
            }
        }
    }

    /// Creates and returns a new instance of the configured embedding model provider.
    /// This is a stub for when the "onnx" feature is not enabled.
    #[cfg(not(feature = "onnx"))]
    pub fn create_embedding_model(&self) -> Result<Arc<Mutex<OnnxEmbeddingModel>>> {
        Err(SagittaEmbedError::feature_not_enabled("onnx"))
    }

    /// Get the type of the model currently handled.
    pub fn get_model_type(&self) -> EmbeddingModelType {
        self.config.model_type.clone()
    }

    /// Returns the path to the ONNX model file, if configured.
    pub fn onnx_model_path(&self) -> Option<&PathBuf> {
        self.config.onnx_model_path.as_ref()
    }

    /// Returns the path to the ONNX tokenizer configuration, if configured.
    pub fn onnx_tokenizer_path(&self) -> Option<&PathBuf> {
        self.config.onnx_tokenizer_path.as_ref()
    }

    /// Gets direct, shareable access to the ONNX provider (if available).
    #[cfg(feature = "onnx")]
    pub fn get_onnx_provider(&self) -> Result<Arc<Mutex<OnnxEmbeddingModel>>> {
        if let Some(provider) = &self.onnx_provider {
            Ok(Arc::clone(provider))
        } else {
            log::error!("Attempted to get ONNX provider, but it was not initialized.");
            Err(SagittaEmbedError::provider("ONNX provider not initialized"))
        }
    }

    #[cfg(not(feature = "onnx"))]
    pub fn get_onnx_provider(&self) -> Result<Arc<Mutex<OnnxEmbeddingModel>>> {
        Err(SagittaEmbedError::feature_not_enabled("onnx"))
    }

    /// Get the configuration used by this handler.
    pub fn config(&self) -> &EmbeddingConfig {
        &self.config
    }

    /// Update the configuration and reinitialize the provider if needed.
    pub fn update_config(&mut self, new_config: &EmbeddingConfig) -> Result<()> {
        new_config.validate()?;
        
        // Check if we need to reinitialize the provider
        let needs_reinit = self.config.model_type != new_config.model_type
            || self.config.onnx_model_path != new_config.onnx_model_path
            || self.config.onnx_tokenizer_path != new_config.onnx_tokenizer_path;

        self.config = new_config.clone();

        if needs_reinit {
            #[cfg(feature = "onnx")]
            {
                self.onnx_provider = None; // Clear existing provider
                if let (Some(model_p), Some(tok_p)) = (&self.config.onnx_model_path, &self.config.onnx_tokenizer_path) {
                    match OnnxEmbeddingModel::new_with_config(model_p, tok_p, &self.config) {
                        Ok(p) => self.onnx_provider = Some(Arc::new(Mutex::new(p))),
                        Err(e) => log::error!("Failed to re-initialize ONNX provider after config change: {}", e),
                    }
                }
            }
        }

        Ok(())
    }
}

// Implement EmbeddingProvider for EmbeddingHandler to maintain compatibility
impl EmbeddingProvider for EmbeddingHandler {
    fn dimension(&self) -> usize {
        self.dimension().unwrap_or(0) // Return 0 if there's an error
    }

    fn model_type(&self) -> EmbeddingModelType {
        self.get_model_type()
    }

    fn embed_batch<'a>(&self, texts: &[&'a str]) -> Result<Vec<Vec<f32>>> {
        self.embed(texts)
    }
}

impl Clone for EmbeddingHandler {
    fn clone(&self) -> Self {
        Self {
            config: self.config.clone(),
            #[cfg(feature = "onnx")]
            onnx_provider: self.onnx_provider.clone(),
            last_used: Instant::now(), // Reset last_used for the clone
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::config::EmbeddingConfig;
    use tempfile::tempdir;
    use std::fs;

    fn create_test_config() -> EmbeddingConfig {
        EmbeddingConfig::default()
    }

    #[test]
    fn test_embedding_handler_new_missing_paths() {
        let config = create_test_config(); // Default config has no paths set
        let result = EmbeddingHandler::new(&config);
        assert!(result.is_err());
    }

    #[test]
    fn test_embedding_handler_get_model_type() {
        let config = EmbeddingConfig::new()
            .with_model_type(EmbeddingModelType::Onnx);
        
        // This will fail validation due to missing paths, but we can test the type
        if let Ok(handler) = EmbeddingHandler::new(&config) {
            assert_eq!(handler.get_model_type(), EmbeddingModelType::Onnx);
        }
    }

    #[cfg(feature = "onnx")]
    #[test]
    fn test_embedding_handler_with_valid_files() {
        let temp_dir = tempdir().unwrap();
        let model_path = temp_dir.path().join("model.onnx");
        let tokenizer_path = temp_dir.path().join("tokenizer.json");

        // Create dummy files
        fs::write(&model_path, "dummy model").unwrap();
        
        // Create minimal valid tokenizer JSON
        let tokenizer_content = serde_json::json!({
            "version": "1.0",
            "truncation": null,
            "padding": null,
            "added_tokens": [],
            "normalizer": null,
            "pre_tokenizer": null,
            "post_processor": null,
            "decoder": null,
            "model": {
                "type": "WordPiece",
                "unk_token": "[UNK]",
                "continuing_subword_prefix": "##",
                "max_input_chars_per_word": 100,
                "vocab": {
                    "[UNK]": 0,
                    "[CLS]": 1,
                    "[SEP]": 2
                }
            }
        });
        fs::write(&tokenizer_path, tokenizer_content.to_string()).unwrap();

        let config = EmbeddingConfig::new_onnx(model_path, tokenizer_path);
        
        // This might still fail if ORT libs aren't found or the dummy model is invalid
        let result = EmbeddingHandler::new(&config);
        if result.is_err() {
            println!("Note: Handler creation failed, likely due to ORT setup or dummy model: {:?}", result.err());
        }
        // For basic testing, we often just check if it doesn't panic and returns Result
    }
} 